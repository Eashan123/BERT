{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "multilabel_bert.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "370f7cf96e524b1c888e9f0a370a8549": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_6f3dae8f2c4047648f5fb754b53bbb7f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_562c95ecf3c842039f853ca187a9addd",
              "IPY_MODEL_1c4303f9bc2f4c898d19c4f77fec1569"
            ]
          }
        },
        "6f3dae8f2c4047648f5fb754b53bbb7f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "562c95ecf3c842039f853ca187a9addd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f1b60a1b3b1f4a63b3baedaf9a6883b3",
            "_dom_classes": [],
            "description": "Converting examples to features",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 1596,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1596,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e2d75008457e489ca3364db90dfac45e"
          }
        },
        "1c4303f9bc2f4c898d19c4f77fec1569": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_21d1bafb6a9b4ab3923ea5b92f2c2cf5",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 1596/1596 [00:01&lt;00:00, 1189.84it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f98af37342114afc863efe6a6df1a41a"
          }
        },
        "f1b60a1b3b1f4a63b3baedaf9a6883b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e2d75008457e489ca3364db90dfac45e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "21d1bafb6a9b4ab3923ea5b92f2c2cf5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f98af37342114afc863efe6a6df1a41a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "064da06a5a934454a13751e3f9152531": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_05868bbb1d9e4c8692173709990245b6",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_66fec7b687924a79bcd4c5107b304451",
              "IPY_MODEL_89f9b3a743254e3d9a0100c627571107"
            ]
          }
        },
        "05868bbb1d9e4c8692173709990245b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "66fec7b687924a79bcd4c5107b304451": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c8fad179ce234e7b9f08b01dc6f4d249",
            "_dom_classes": [],
            "description": "Converting examples to features",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 5,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 5,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_59d0113f213842ceaa720e44869a07eb"
          }
        },
        "89f9b3a743254e3d9a0100c627571107": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6c7e9bb7ec2347d8bc931bb8d5277990",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 5/5 [00:00&lt;00:00, 136.94it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bc7ca66647594af698bcd777147f76aa"
          }
        },
        "c8fad179ce234e7b9f08b01dc6f4d249": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "59d0113f213842ceaa720e44869a07eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6c7e9bb7ec2347d8bc931bb8d5277990": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bc7ca66647594af698bcd777147f76aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Eashan123/BERT/blob/master/multilabel_bert.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SLA3h5pB7E1Y",
        "colab_type": "text"
      },
      "source": [
        "#### Why multilabel classification:\n",
        "multi-label classification assumes that a document can simultaneously and independently assigned to multiple labels or classes. Multi-label classification has many real world applications such as categorising businesses or assigning multiple genres to a movie. In the world of customer service, this technique can be used to identify multiple intents for a customer’s email. <br>\n",
        "****Why is it a better alternative than RNN?**** <br>\n",
        "BERT is a multilingual transformer based model that has achieved state-of-the-art results on various NLP tasks. BERT is a bidirectional model that is based on the transformer architecture, it replaces the sequential nature of RNN (LSTM & GRU) with a much faster Attention-based approach. The model is also pre-trained on two unsupervised tasks, masked language modeling and next sentence prediction."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QsWwV-yk7E1g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# #https://github.com/strongio/keras-bert/blob/master/keras-bert.ipynb"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xUQNqcdS76m-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !pip install bert"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QcunK6aI8IV8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !pip install keras-bert"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AUngMo6V8jB0",
        "colab_type": "code",
        "outputId": "36f63f73-7446-4641-b5f3-4110dc5c8cf9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "!pip install bert-tensorflow"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting bert-tensorflow\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/66/7eb4e8b6ea35b7cc54c322c816f976167a43019750279a8473d355800a93/bert_tensorflow-1.0.1-py2.py3-none-any.whl (67kB)\n",
            "\r\u001b[K     |████▉                           | 10kB 27.3MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 20kB 31.7MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 30kB 37.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 40kB 40.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 51kB 41.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 61kB 43.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 71kB 10.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from bert-tensorflow) (1.12.0)\n",
            "Installing collected packages: bert-tensorflow\n",
            "Successfully installed bert-tensorflow-1.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MSGhW2sC_Lg1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -U -q PyDrive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h8raCs8Y_XjK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jw06BduEEQr9",
        "colab_type": "code",
        "outputId": "8f0e9b0f-492f-42c3-c82e-ec3277a4ab99",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "#We are mounting drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xajzwm57_X2a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bhlSC5AA7E1n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Importing Packages\n",
        "\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import tensorflow_hub as hub\n",
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "from bert.tokenization import FullTokenizer\n",
        "from tqdm import tqdm_notebook\n",
        "from tensorflow.keras import backend as K\n",
        "# from tensorflow.keras.callbacks import callback"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GP8H6xaw7E1r",
        "colab_type": "code",
        "outputId": "61eff926-808f-454d-c932-219d060320e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# import tqdm.keras as tk\n",
        "# # from tqdm.keras import TqdmCallback\n",
        "# from keras.models import model_from_yaml\n",
        "from tensorflow.keras.models import load_model\n",
        "from bert import run_classifier\n",
        "from bert import optimization\n",
        "from bert import tokenization"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/optimization.py:87: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Faig7TLf7E1x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Initialize session\n",
        "sess = tf.Session()\n",
        "bert_path = \"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\" #lower case model, the smallest in size."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PGSFLPId7E12",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Params for bert model and tokenization\n",
        "# Variable configuration\n",
        "\n",
        "max_seq_length = 100\n",
        "# EMBEDDING_DIM = 50 # could be 100/150/200\n",
        "VALIDATION_SPLIT = 0.15\n",
        "BATCH_SIZE = 200\n",
        "EPOCHS = 1 #to save time\n",
        "possible_labels = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XaHvgcZz7E16",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DATA_COLUMN = 'text'\n",
        "LABEL_COLUMN = 'labels'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c51h0zrX-hde",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "link = 'https://drive.google.com/open?id=1a9V_WyDXpgTg_nHyI5dRNIOI3SSQrScP' "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5SrCfjaoHMZx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "link_unknown_data = 'https://drive.google.com/open?id=1qjkuI_3uOBKNyowTMv3a5Xf-aJWbOldz'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TCeSmz_5-oH8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fluff, id = link.split('=')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tH0c5OluIjdy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fluff_p, id_p = link_unknown_data.split('=')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wBgzVo7gHzGV",
        "colab_type": "code",
        "outputId": "6b9b6792-3283-4402-b561-a611367bc423",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print (id) # Verify that you have everything after '='"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1qjkuI_3uOBKNyowTMv3a5Xf-aJWbOldz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BgRPOSuM-pHz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "downloaded = drive.CreateFile({'id':id}) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rA7SsMYBHrj_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "downloaded_p = drive.CreateFile({'id':id_p}) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FU4CtWoX_qjZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "downloaded.GetContentFile('Filename.csv')  \n",
        "train_df = pd.read_csv('Filename.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_dbfpXnaH1qT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "downloaded_p.GetContentFile('Filename.xlsx')  \n",
        "p_dat = pd.read_excel('Filename.xlsx')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_kyHQyrJ7E1_",
        "colab_type": "text"
      },
      "source": [
        "### Data\n",
        "First, we load the sample data Statement Toxicity data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FuhfaUdh7E2B",
        "colab_type": "code",
        "outputId": "e6880823-e25e-48ea-8aff-0c3e3936d496",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# train_df = pd.read_csv('/BERT/data/train.csv')\n",
        "trn_df = train_df.sample(frac=0.01,random_state = 42) \n",
        "# trn_df = train_df\n",
        "trn_df.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1596, 8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ToNwjQya7E2W",
        "colab_type": "code",
        "outputId": "8016727c-9c04-4c9a-8bf8-1ee195cdb3a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        }
      },
      "source": [
        " trn_df.head(3)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>comment_text</th>\n",
              "      <th>toxic</th>\n",
              "      <th>severe_toxic</th>\n",
              "      <th>obscene</th>\n",
              "      <th>threat</th>\n",
              "      <th>insult</th>\n",
              "      <th>identity_hate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>119105</th>\n",
              "      <td>7ca72b5b9c688e9e</td>\n",
              "      <td>Geez, are you forgetful!  We've already discus...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>131631</th>\n",
              "      <td>c03f72fd8f8bf54f</td>\n",
              "      <td>Carioca RFA \\n\\nThanks for your support on my ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>125326</th>\n",
              "      <td>9e5b8e8fc1ff2e84</td>\n",
              "      <td>\"\\n\\n Birthday \\n\\nNo worries, It's what I do ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                      id  ... identity_hate\n",
              "119105  7ca72b5b9c688e9e  ...             0\n",
              "131631  c03f72fd8f8bf54f  ...             0\n",
              "125326  9e5b8e8fc1ff2e84  ...             0\n",
              "\n",
              "[3 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eWYEV5Wo7E2Z",
        "colab_type": "text"
      },
      "source": [
        "#### Adding a new column as per the requirement of bert"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9LwJs6aH7E2a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trn_df['labels'] = list(zip(trn_df.toxic.tolist(), trn_df.severe_toxic.tolist(), trn_df.obscene.tolist(), trn_df.threat.tolist(),  trn_df.insult.tolist(), trn_df.identity_hate.tolist()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a7vEwQnc7E2e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sPaS3iUf7E2l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Some text processing"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lU730HxY7E2q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trn_df['text'] = trn_df['comment_text'].apply(lambda x: x.replace('\\n', ' '))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8XU5BZBJ7E2w",
        "colab_type": "code",
        "outputId": "add89cff-1b47-4181-a25d-b9dc542de3f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        }
      },
      "source": [
        "trn_df.head(3)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>comment_text</th>\n",
              "      <th>toxic</th>\n",
              "      <th>severe_toxic</th>\n",
              "      <th>obscene</th>\n",
              "      <th>threat</th>\n",
              "      <th>insult</th>\n",
              "      <th>identity_hate</th>\n",
              "      <th>labels</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>119105</th>\n",
              "      <td>7ca72b5b9c688e9e</td>\n",
              "      <td>Geez, are you forgetful!  We've already discus...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>(0, 0, 0, 0, 0, 0)</td>\n",
              "      <td>Geez, are you forgetful!  We've already discus...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>131631</th>\n",
              "      <td>c03f72fd8f8bf54f</td>\n",
              "      <td>Carioca RFA \\n\\nThanks for your support on my ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>(0, 0, 0, 0, 0, 0)</td>\n",
              "      <td>Carioca RFA   Thanks for your support on my re...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>125326</th>\n",
              "      <td>9e5b8e8fc1ff2e84</td>\n",
              "      <td>\"\\n\\n Birthday \\n\\nNo worries, It's what I do ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>(0, 0, 0, 0, 0, 0)</td>\n",
              "      <td>\"   Birthday   No worries, It's what I do ;)En...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                      id  ...                                               text\n",
              "119105  7ca72b5b9c688e9e  ...  Geez, are you forgetful!  We've already discus...\n",
              "131631  c03f72fd8f8bf54f  ...  Carioca RFA   Thanks for your support on my re...\n",
              "125326  9e5b8e8fc1ff2e84  ...  \"   Birthday   No worries, It's what I do ;)En...\n",
              "\n",
              "[3 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j3oJnme37E25",
        "colab_type": "text"
      },
      "source": [
        "#### Converting data to array for the input to the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0jbX-aDW7E26",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_text = trn_df['text'].tolist()\n",
        "train_text = [' '.join(t.split()[0:max_seq_length]) for t in train_text]\n",
        "train_text = np.array(train_text, dtype=object)[:, np.newaxis]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wwEzDfLi7E28",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_label = trn_df['labels'].values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BC1NoyZK7E3F",
        "colab_type": "code",
        "outputId": "5d9c853a-5a7c-40ea-c252-44966feb2f57",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "print('train_text shape -> {} \\ntrain_text[0] -> {} \\ntrain label shape -> {} \\ntrain label -> {} \\n'.format(train_text.shape, train_text[0], train_label.shape, train_label[0]))\n",
        "# print('test_text shape -> {} \\ntest_text[0] -> {} \\ntrain label shape -> {} \\n'.format(test_text.shape, test_text[0], test_label.shape))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train_text shape -> (1596, 1) \n",
            "train_text[0] -> [\"Geez, are you forgetful! We've already discussed why Marx was not an anarchist, i.e. he wanted to use a State to mold his 'socialist man.' Ergo, he is a statist - the opposite of an anarchist. I know a guy who says that, when he gets old and his teeth fall out, he'll quit eating meat. Would you call him a vegetarian?\"] \n",
            "train label shape -> (1596,) \n",
            "train label -> (0, 0, 0, 0, 0, 0) \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HWJP5mZv7E3J",
        "colab_type": "text"
      },
      "source": [
        "### Tokenize\n",
        "\n",
        "***What are we doing here?*** <br>\n",
        "Because BERT is a pretrained model that expects input data in a specific format, we will need: <br>\n",
        "a. special tokens to mark the beginning ([CLS]) and separation/end of sentences ([SEP])  -> refer convert_text_to_examples(), InputExample(object) <br>\n",
        "b. tokens that conforms with the fixed vocabulary used in BERT -> Convert Single Example() <br>\n",
        "c. token IDs from BERT’s tokenizer -> create_tokenizer_from_hub_module() <br>\n",
        "d. mask IDs to indicate which elements in the sequence are tokens and which are padding elements -> convert_examples_to_features(), convert_single_example() <br>\n",
        "e. segment IDs used to distinguish different sentences -> convert_examples_to_features(), convert_single_example() <br>\n",
        "f. positional embeddings used to show token position with in the sequence (input_ids) -> convert_examples_to_features(), convert_single_example() <br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SIQTrcRg7E3K",
        "colab_type": "text"
      },
      "source": [
        "***Tokenizer example for a better understanding***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5kJE43w87E3K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# #Demo\n",
        "\n",
        "# text = \"Here is the sentence I want embeddings for.\"\n",
        "# marked_text = \"[CLS] \" + text + \" [SEP]\"\n",
        "\n",
        "# # Tokenize our sentence with the BERT tokenizer.\n",
        "# tokenized_text = tokenizer.tokenize(marked_text)\n",
        "\n",
        "# # Print out the tokens.\n",
        "# print (tokenized_text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ckrex-qD7E3O",
        "colab_type": "text"
      },
      "source": [
        "**After breaking the text into tokens, we then have to convert the sentence from a list of strings to a list of vocabulary indeces.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i6WYePWF7E3P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # Define a new example sentence with multiple meanings of the word \"bank\"\n",
        "# text = \"He went to the prison cell with his cell phone to extract blood cell samples from inmates\"\n",
        "\n",
        "# # Add the special tokens.\n",
        "# marked_text = \"[CLS] \" + text + \" [SEP]\"\n",
        "\n",
        "# # Split the sentence into tokens.\n",
        "# tokenized_text = tokenizer.tokenize(marked_text)\n",
        "\n",
        "# # Map the token strings to their vocabulary indeces.\n",
        "# indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
        "\n",
        "# # Display the words with their indeces.\n",
        "# for tup in zip(tokenized_text, indexed_tokens):\n",
        "# #     print('{:<12} {:>6,}'.format(tup[0], tup[1]))\n",
        "#     print('text -> {:<12} input_ids -> {:>6,}'.format(tup[0], tup[1]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ukpWXV67E3S",
        "colab_type": "text"
      },
      "source": [
        "****Segment ID****\n",
        "BERT expects 1s and 0s to distinguish between the two sentences. That is, for each token in “tokenized_text,” we must specify which sentence it belongs to: sentence 0 (a series of 0s) or sentence 1 (a series of 1s). <br>\n",
        "\n",
        "For example, single-sentence inputs only require a series of 1s, so we will create a vector of 1s for each token in our input sentence."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E8n-EN-i7E3T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#  #Mark each of the 22 tokens as belonging to sentence \"1\".\n",
        "# segments_ids = [1] * len(tokenized_text)\n",
        "\n",
        "# print (segments_ids)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yg8_2oYt7E3W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_tokenizer_from_hub_module():\n",
        "    \"\"\"Get the vocab file and casing info from the Hub module.\"\"\"\n",
        "    bert_module =  hub.Module(bert_path)\n",
        "    tokenization_info = bert_module(signature=\"tokenization_info\", as_dict=True)\n",
        "    vocab_file, do_lower_case = sess.run(\n",
        "        [\n",
        "            tokenization_info[\"vocab_file\"],\n",
        "            tokenization_info[\"do_lower_case\"],\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    return FullTokenizer(vocab_file=vocab_file, do_lower_case=do_lower_case)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sf4kiteO7E3b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class PaddingInputExample(object):\n",
        "    \"\"\"Fake example so the num input examples is a multiple of the batch size.\n",
        "  When running eval/predict on the TPU, we need to pad the number of examples\n",
        "  to be a multiple of the batch size, because the TPU requires a fixed batch\n",
        "  size. The alternative is to drop the last batch, which is bad because it means\n",
        "  the entire output data won't be generated.\n",
        "  We use this class instead of `None` because treating `None` as padding\n",
        "  battches could cause silent errors.\n",
        "  \"\"\"\n",
        "\n",
        "class InputExample(object):\n",
        "    \"\"\"A single training/test example for simple sequence classification.\"\"\"\n",
        "\n",
        "    def __init__(self, guid, text_a, text_b=None, label=None):\n",
        "        \"\"\"Constructs a InputExample.\n",
        "    Args:\n",
        "      guid: Unique id for the example.\n",
        "      text_a: string. The untokenized text of the first sequence. For single\n",
        "        sequence tasks, only this sequence must be specified.\n",
        "      text_b: (Optional) string. The untokenized text of the second sequence.\n",
        "        Only must be specified for sequence pair tasks.\n",
        "      label: (Optional) string. The label of the example. This should be\n",
        "        specified for train and dev examples, but not for test examples.\n",
        "    \"\"\"\n",
        "        self.guid = guid\n",
        "        self.text_a = text_a\n",
        "        self.text_b = text_b\n",
        "        self.label = label\n",
        "\n",
        "\n",
        "def convert_single_example(tokenizer, example, max_seq_length=100):\n",
        "    \"\"\"Converts a single `InputExample` into a single `InputFeatures`.\"\"\"\n",
        "\n",
        "    if isinstance(example, PaddingInputExample):\n",
        "        input_ids = [0] * max_seq_length\n",
        "        input_mask = [0] * max_seq_length\n",
        "        segment_ids = [0] * max_seq_length\n",
        "        label = 0\n",
        "        return input_ids, input_mask, segment_ids, label\n",
        "\n",
        "    tokens_a = tokenizer.tokenize(example.text_a)\n",
        "    if len(tokens_a) > max_seq_length - 2:\n",
        "        tokens_a = tokens_a[0 : (max_seq_length - 2)]\n",
        "\n",
        "    tokens = []\n",
        "    segment_ids = []\n",
        "    tokens.append(\"[CLS]\")\n",
        "    segment_ids.append(0)\n",
        "    for token in tokens_a:\n",
        "        tokens.append(token)\n",
        "        segment_ids.append(0)\n",
        "    tokens.append(\"[SEP]\")\n",
        "    segment_ids.append(0)\n",
        "\n",
        "    input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "\n",
        "    # The mask has 1 for real tokens and 0 for padding tokens. Only real\n",
        "    # tokens are attended to.\n",
        "    input_mask = [1] * len(input_ids)\n",
        "\n",
        "    # Zero-pad up to the sequence length.\n",
        "    while len(input_ids) < max_seq_length:\n",
        "        input_ids.append(0)\n",
        "        input_mask.append(0)\n",
        "        segment_ids.append(0)\n",
        "\n",
        "    assert len(input_ids) == max_seq_length\n",
        "    assert len(input_mask) == max_seq_length\n",
        "    assert len(segment_ids) == max_seq_length\n",
        "\n",
        "    return input_ids, input_mask, segment_ids, example.label\n",
        "\n",
        "def convert_examples_to_features(tokenizer, examples, max_seq_length=100): ### calls convert single example\n",
        "    \"\"\"Convert a set of `InputExample`s to a list of `InputFeatures`.\"\"\"\n",
        "\n",
        "    input_ids, input_masks, segment_ids, labels = [], [], [], []\n",
        "    for example in tqdm_notebook(examples, desc=\"Converting examples to features\"):\n",
        "        input_id, input_mask, segment_id, label = convert_single_example(\n",
        "            tokenizer, example, max_seq_length\n",
        "        )\n",
        "        input_ids.append(input_id)\n",
        "        input_masks.append(input_mask)\n",
        "        segment_ids.append(segment_id)\n",
        "        labels.append(label)\n",
        "    return (\n",
        "        np.array(input_ids),\n",
        "        np.array(input_masks),\n",
        "        np.array(segment_ids),\n",
        "        np.array(labels),\n",
        "#         np.array(labels).reshape(-1, 1),\n",
        "        \n",
        "    )\n",
        "\n",
        "def convert_text_to_examples(texts, labels):\n",
        "    \"\"\"Create InputExamples\"\"\"\n",
        "    InputExamples = []\n",
        "    for text, label in zip(texts, labels):\n",
        "        InputExamples.append(\n",
        "            InputExample(guid=None, text_a=\" \".join(text), text_b=None, label=label)\n",
        "        )\n",
        "    return InputExamples"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6QIZshER7E3e",
        "colab_type": "text"
      },
      "source": [
        "***Instantiate tokenizer***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mhQZ6oWa7E3f",
        "colab_type": "code",
        "outputId": "0eafd6cb-ccfc-44c8-9d55-2c1481932b6f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "tokenizer = create_tokenizer_from_hub_module()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0LYnNnlg7E3i",
        "colab_type": "text"
      },
      "source": [
        "***Convert our data to Bert format***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ovQ0RytU7E3k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_examples = convert_text_to_examples(train_text, train_label)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ND3UdDVX7E3p",
        "colab_type": "code",
        "outputId": "40192363-2525-4338-9b34-9ab19056323d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "type(train_examples), train_examples[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(list, <__main__.InputExample at 0x7fe80ed847f0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F62Y8oR97E3u",
        "colab_type": "code",
        "outputId": "9701e2f6-6138-43aa-a532-0c559f4f21b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "370f7cf96e524b1c888e9f0a370a8549",
            "6f3dae8f2c4047648f5fb754b53bbb7f",
            "562c95ecf3c842039f853ca187a9addd",
            "1c4303f9bc2f4c898d19c4f77fec1569",
            "f1b60a1b3b1f4a63b3baedaf9a6883b3",
            "e2d75008457e489ca3364db90dfac45e",
            "21d1bafb6a9b4ab3923ea5b92f2c2cf5",
            "f98af37342114afc863efe6a6df1a41a"
          ]
        }
      },
      "source": [
        "# Convert to features\n",
        "(train_input_ids, train_input_masks, train_segment_ids, train_labels \n",
        ") = convert_examples_to_features(tokenizer, train_examples, max_seq_length=max_seq_length)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "370f7cf96e524b1c888e9f0a370a8549",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Converting examples to features', max=1596, style=ProgressSty…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Xew7Fzr7E33",
        "colab_type": "code",
        "outputId": "2643eacb-aa2f-4142-902b-084c4922467e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "type(train_input_ids), train_input_ids.shape, train_input_masks.shape, train_segment_ids.shape, train_labels.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(numpy.ndarray, (1596, 100), (1596, 100), (1596, 100), (1596, 6))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hble4HXE7E39",
        "colab_type": "text"
      },
      "source": [
        "#### Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FgtjW1Z87E3-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BertLayer(tf.keras.layers.Layer):\n",
        "    def __init__(\n",
        "        self,\n",
        "        n_fine_tune_layers=10,\n",
        "        pooling=\"first\",\n",
        "        bert_path=\"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\", #This is the model we choose\n",
        "        **kwargs,\n",
        "    ):\n",
        "        self.n_fine_tune_layers = n_fine_tune_layers\n",
        "        self.trainable = True\n",
        "        self.output_size = 768\n",
        "        self.pooling = pooling\n",
        "        self.bert_path = bert_path\n",
        "        if self.pooling not in [\"first\", \"mean\"]:\n",
        "            raise NameError(\n",
        "                f\"Undefined pooling type (must be either first or mean, but is {self.pooling}\"\n",
        "            )\n",
        "\n",
        "        super(BertLayer, self).__init__(**kwargs)\n",
        "\n",
        "    def get_config(self):\n",
        "\n",
        "        config = super().get_config().copy()\n",
        "        config.update({\n",
        "            'n_fine_tune_layers': self.n_fine_tune_layers,\n",
        "            'trainable': self.trainable,\n",
        "            'output_size': self.output_size,\n",
        "            'pooling': self.pooling,\n",
        "            'bert_path': self.bert_path,\n",
        "        })\n",
        "        return config\n",
        "    \n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.bert = hub.Module(\n",
        "            self.bert_path, trainable=self.trainable, name=f\"{self.name}_module\"\n",
        "        )\n",
        "\n",
        "        # Remove unused layers\n",
        "        trainable_vars = self.bert.variables\n",
        "        if self.pooling == \"first\":\n",
        "            trainable_vars = [var for var in trainable_vars if not \"/cls/\" in var.name]\n",
        "            trainable_layers = [\"pooler/dense\"]\n",
        "\n",
        "        elif self.pooling == \"mean\":\n",
        "            trainable_vars = [\n",
        "                var\n",
        "                for var in trainable_vars\n",
        "                if not \"/cls/\" in var.name and not \"/pooler/\" in var.name\n",
        "            ]\n",
        "            trainable_layers = []\n",
        "        else:\n",
        "            raise NameError(\n",
        "                f\"Undefined pooling type (must be either first or mean, but is {self.pooling}\"\n",
        "            )\n",
        "\n",
        "        # Select how many layers to fine tune\n",
        "        for i in range(self.n_fine_tune_layers):\n",
        "            trainable_layers.append(f\"encoder/layer_{str(11 - i)}\")\n",
        "\n",
        "        # Update trainable vars to contain only the specified layers\n",
        "        trainable_vars = [\n",
        "            var\n",
        "            for var in trainable_vars\n",
        "            if any([l in var.name for l in trainable_layers])\n",
        "        ]\n",
        "\n",
        "        # Add to trainable weights\n",
        "        for var in trainable_vars:\n",
        "            self._trainable_weights.append(var)\n",
        "\n",
        "        for var in self.bert.variables:\n",
        "            if var not in self._trainable_weights:\n",
        "                self._non_trainable_weights.append(var)\n",
        "\n",
        "        super(BertLayer, self).build(input_shape)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        inputs = [K.cast(x, dtype=\"int32\") for x in inputs]\n",
        "        input_ids, input_mask, segment_ids = inputs\n",
        "        bert_inputs = dict(\n",
        "            input_ids=input_ids, input_mask=input_mask, segment_ids=segment_ids\n",
        "        )\n",
        "        if self.pooling == \"first\":\n",
        "            pooled = self.bert(inputs=bert_inputs, signature=\"tokens\", as_dict=True)[\n",
        "                \"pooled_output\"\n",
        "            ]\n",
        "        elif self.pooling == \"mean\":\n",
        "            result = self.bert(inputs=bert_inputs, signature=\"tokens\", as_dict=True)[\n",
        "                \"sequence_output\"\n",
        "            ]\n",
        "\n",
        "            mul_mask = lambda x, m: x * tf.expand_dims(m, axis=-1)\n",
        "            masked_reduce_mean = lambda x, m: tf.reduce_sum(mul_mask(x, m), axis=1) / (\n",
        "                    tf.reduce_sum(m, axis=1, keepdims=True) + 1e-10)\n",
        "            input_mask = tf.cast(input_mask, tf.float32)\n",
        "            pooled = masked_reduce_mean(result, input_mask)\n",
        "        else:\n",
        "            raise NameError(f\"Undefined pooling type (must be either first or mean, but is {self.pooling}\")\n",
        "\n",
        "        return pooled\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return (input_shape[0], self.output_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j8PZZQEW7E4C",
        "colab_type": "text"
      },
      "source": [
        "****Defining our model****"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rMQqEfJi7E4D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Build model\n",
        "def build_model(max_seq_length): \n",
        "    in_id = tf.keras.layers.Input(shape=(max_seq_length,), name=\"input_ids\")\n",
        "    in_mask = tf.keras.layers.Input(shape=(max_seq_length,), name=\"input_masks\")\n",
        "    in_segment = tf.keras.layers.Input(shape=(max_seq_length,), name=\"segment_ids\")\n",
        "    \n",
        "    #This is the input in list form to be fed to the model\n",
        "    bert_inputs = [in_id, in_mask, in_segment]\n",
        "    \n",
        "    bert_output = BertLayer(n_fine_tune_layers=3, pooling=\"first\")(bert_inputs) #calling the preloaded BERT model we have installed\n",
        "    \n",
        "    dense = tf.keras.layers.Dense(256, activation='relu')(bert_output) # Attaching our model output here\n",
        "    pred = tf.keras.layers.Dense(len(possible_labels), activation='sigmoid')(dense)\n",
        "    \n",
        "    model = tf.keras.models.Model(inputs=bert_inputs, outputs=pred)\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    model.summary()\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6erufULE7E4H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def initialize_vars(sess):\n",
        "    sess.run(tf.local_variables_initializer())\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    sess.run(tf.tables_initializer())\n",
        "    K.set_session(sess)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XOanjp9m7E4L",
        "colab_type": "code",
        "outputId": "0bddae91-8696-4c87-cfbf-bc7f747d7d2d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 649
        }
      },
      "source": [
        "modll_ = build_model(max_seq_length)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_ids (InputLayer)          [(None, 100)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_masks (InputLayer)        [(None, 100)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "segment_ids (InputLayer)        [(None, 100)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "bert_layer (BertLayer)          (None, 768)          110104890   input_ids[0][0]                  \n",
            "                                                                 input_masks[0][0]                \n",
            "                                                                 segment_ids[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 256)          196864      bert_layer[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 6)            1542        dense[0][0]                      \n",
            "==================================================================================================\n",
            "Total params: 110,303,296\n",
            "Trainable params: 22,052,614\n",
            "Non-trainable params: 88,250,682\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BoIKvfuv7E4O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Instantiate variables\n",
        "initialize_vars(sess)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OxeZc36j7E4R",
        "colab_type": "code",
        "outputId": "b1e233c6-cadf-48f7-b1db-98b117a744e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_input_ids.shape, train_input_masks.shape, train_segment_ids.shape, train_labels.shape "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1596, 100), (1596, 100), (1596, 100), (1596, 6))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cotxTzhW7E4X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Defining NBatchLogger for logging details for training\n",
        "class NBatchLogger(tf.keras.callbacks.Callback):\n",
        "    def __init__(self, display):\n",
        "        self.seen = 0\n",
        "        self.display = display\n",
        "\n",
        "    def on_batch_end(self, batch, logs={}):\n",
        "        self.seen += logs.get('size', 0)\n",
        "        if self.seen % self.display == 0:\n",
        "            metrics_log = ''\n",
        "            for k in self.params['metrics']:\n",
        "                if k in logs:\n",
        "                    val = logs[k]\n",
        "                    if abs(val) > 1e-3:\n",
        "                        metrics_log += ' - %s: %.4f' % (k, val)\n",
        "                    else:\n",
        "                        metrics_log += ' - %s: %.4e' % (k, val)\n",
        "            print('{}/{} ... {}'.format(self.seen,\n",
        "                                        self.params['samples'],\n",
        "                                        metrics_log))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AQ8AEoAR7E4b",
        "colab_type": "text"
      },
      "source": [
        "****Transfer Learning****"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Dgpr8SINfpQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "out_batch = NBatchLogger(display=1000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "226wD95e7E4c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "modll_.fit([train_input_ids, train_input_masks, train_segment_ids], train_labels, batch_size=BATCH_SIZE, epochs=EPOCHS, validation_split=VALIDATION_SPLIT, callbacks=[out_batch])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vzjb6CWq7E4e",
        "colab_type": "text"
      },
      "source": [
        "#### Saving Model\n",
        "\n",
        "Not working, needs some changes in it's original run config file, due to the different architecture followed by bert."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VIs1wgDg7E4e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # #refer: --> https://stackoverflow.com/questions/58678836/notimplementederror-layers-with-arguments-in-init-must-override-get-conf\n",
        "\n",
        "modll_.save('/content/drive/My Drive/BertModel.h5')\n",
        "\n",
        "# # #or\n",
        "\n",
        "# # # serialize model to YAML\n",
        "# model_yaml = modl_.to_yaml()\n",
        "# with open(\"model.yaml\", \"w\") as yaml_file:\n",
        "#     yaml_file.write(model_yaml)\n",
        "# # serialize weights to HDF5\n",
        "# modl_.save_weights(\"bert_model_keras.h5\")\n",
        "# print(\"Saved model to disk\") "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qTEb0JwL7E4g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # predictions before we clear and reload model\n",
        "pre_save_preds = modll_.predict([test_input_ids[0:100], \n",
        "                                test_input_masks[0:100], \n",
        "                                test_segment_ids[0:100]]\n",
        "                              ) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJFDmfzeWbwZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # A file ID looks like: laggVyWshwcyP6kEI-y_W3P8D26sz\n",
        "# listed = drive.ListFile({'q': \"title contains '.h5' and 'root' in parents\"}).GetList()\n",
        "# for file in listed:\n",
        "#     print('title {}, id {}'.format(file['title'], file['id']))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZii6O6A7E4i",
        "colab_type": "code",
        "outputId": "71b6e6c3-43fe-4e8a-cd6d-7237bd7fabe2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "source": [
        "# Clear and load model\n",
        "model = None\n",
        "model = build_model(max_seq_length)\n",
        "# initialize_vars(sess)\n",
        "# model.load_weights('BertModel.h5')\n",
        "model.load_weights('/content/drive/My Drive/BertModel.h5')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_ids (InputLayer)          [(None, 100)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_masks (InputLayer)        [(None, 100)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "segment_ids (InputLayer)        [(None, 100)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "bert_layer_1 (BertLayer)        (None, 768)          110104890   input_ids[0][0]                  \n",
            "                                                                 input_masks[0][0]                \n",
            "                                                                 segment_ids[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 256)          196864      bert_layer_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 6)            1542        dense_2[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 110,303,296\n",
            "Trainable params: 22,052,614\n",
            "Non-trainable params: 88,250,682\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jlwbaGPZ7E4l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "post_save_preds = model.predict([test_input_ids[0:100], \n",
        "                                test_input_masks[0:100], \n",
        "                                test_segment_ids[0:100]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YvRnobbn7E4n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# type(post_save_preds), post_save_preds.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hvMKrGgu7E4p",
        "colab_type": "text"
      },
      "source": [
        "***Displaying Predicted Results***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oJ2L4Fkx7E4p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred_dict = {}\n",
        "list_ = []\n",
        "# \"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"\n",
        "for i in post_save_preds:\n",
        "    pred_dict['toxic'] = str((i[0]*100)) + ' %'\n",
        "    pred_dict['severe_toxic'] = str(i[1]*100) + ' %'\n",
        "    pred_dict['obscene'] = str(i[2]*100) + ' %'\n",
        "    pred_dict['threat'] = str(i[3]*100) + ' %'\n",
        "    pred_dict['insult'] = str(i[4]*100) + ' %'\n",
        "    pred_dict['identity_hate'] = str(i[5]*100) + ' %'\n",
        "    list_.append(pred_dict)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WBOW3ZHP7E4r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cnt = 0\n",
        "for i in range(len(list_)):\n",
        "    cnt += 1\n",
        "    if cnt < 5:\n",
        "        print(list_[i], \"\\n\")\n",
        "    else:\n",
        "        break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SX4XXkQJ7E4w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.all(pre_save_preds == post_save_preds) # Are they the same?"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ewpwvedg7E4z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ts_HEH257E41",
        "colab_type": "text"
      },
      "source": [
        "#### Prediction on unknown data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NmXdXd4F7E41",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "p_dat = pd.read_excel(r'C:/Users/A716717/Eashan_practice/study/practice/data/val_mini.xlsx')\n",
        "p_dat.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jWIN-Sc47E43",
        "colab_type": "text"
      },
      "source": [
        "***Data Preprocessing***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BGUmQurH7E44",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "p_dat['labels'] = list(zip(p_dat.toxic.tolist(), p_dat.severe_toxic.tolist(), p_dat.obscene.tolist(), p_dat.threat.tolist(), p_dat.insult.tolist(), p_dat.identity_hate.tolist()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OumoUoR_7E46",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "p_text = p_dat['comment_text'].tolist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UnN0l6PK7E48",
        "colab_type": "code",
        "outputId": "2d910bec-da38-4a37-a9bc-92ae5b241181",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "p_text"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\":If you have a look back at the source, the information I updated was the correct form. I can only guess the source hadn't updated. I shall update the information once again but thank you for your message.\",\n",
              " \"I don't anonymously edit articles at all.\",\n",
              " 'Thank you for understanding. I think very highly of you and would not revert without discussion.',\n",
              " 'Please do not add nonsense to Wikipedia. Such edits are considered vandalism and quickly undone. If you would like to experiment, please use the sandbox instead. Thank you.   -',\n",
              " ':Dear god this site is horrible.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04j2JwdU7E4_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "p_text = [' '.join(t.split()[0:max_seq_length]) for t in p_text]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HeX0LJAy7E5E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "p_text = np.array(p_text, dtype=object)[:, np.newaxis]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HFAjlJUt7E5H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "p_label = p_dat['labels'].values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gurv2bWY7E5J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#To do\n",
        "p_examples = convert_text_to_examples(p_text, p_label)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1q9zkswT7E5L",
        "colab_type": "code",
        "outputId": "f3dff56a-b97f-4223-9a2d-4ec03de79ea6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "064da06a5a934454a13751e3f9152531",
            "05868bbb1d9e4c8692173709990245b6",
            "66fec7b687924a79bcd4c5107b304451",
            "89f9b3a743254e3d9a0100c627571107",
            "c8fad179ce234e7b9f08b01dc6f4d249",
            "59d0113f213842ceaa720e44869a07eb",
            "6c7e9bb7ec2347d8bc931bb8d5277990",
            "bc7ca66647594af698bcd777147f76aa"
          ]
        }
      },
      "source": [
        "(p_input_ids, p_input_masks, p_segment_ids, train_labels \n",
        ") = convert_examples_to_features(tokenizer, p_examples, max_seq_length=max_seq_length)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "064da06a5a934454a13751e3f9152531",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Converting examples to features', max=5, style=ProgressStyle(…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i3wfo7l_7E5N",
        "colab_type": "text"
      },
      "source": [
        "#### Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uRvRAiuS7E5N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "p_preds = model.predict([p_input_ids, \n",
        "                                p_input_masks, \n",
        "                                p_segment_ids])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UkUQwZ1c7E5P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred_dict = {}\n",
        "list_p = []\n",
        "# \"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"\n",
        "for i in p_preds:\n",
        "    pred_dict['toxic'] = str((i[0]*100)) + ' %'\n",
        "    pred_dict['severe_toxic'] = str(i[1]*100) + ' %'\n",
        "    pred_dict['obscene'] = str(i[2]*100) + ' %'\n",
        "    pred_dict['threat'] = str(i[3]*100) + ' %'\n",
        "    pred_dict['insult'] = str(i[4]*100) + ' %'\n",
        "    pred_dict['identity_hate'] = str(i[5]*100) + ' %'\n",
        "    list_p.append(pred_dict)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A56ABEMP7E5S",
        "colab_type": "code",
        "outputId": "154972ae-ca4e-4792-c3fc-32090a7ddc01",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "source": [
        "for i in range(len(list_p)):\n",
        "    print(list_p[i], \"\\n\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'toxic': '9.895411133766174 %', 'severe_toxic': '0.05812942981719971 %', 'obscene': '0.2048194408416748 %', 'threat': '0.08640885353088379 %', 'insult': '0.5824130028486252 %', 'identity_hate': '0.07198824314400554 %'} \n",
            "\n",
            "{'toxic': '9.895411133766174 %', 'severe_toxic': '0.05812942981719971 %', 'obscene': '0.2048194408416748 %', 'threat': '0.08640885353088379 %', 'insult': '0.5824130028486252 %', 'identity_hate': '0.07198824314400554 %'} \n",
            "\n",
            "{'toxic': '9.895411133766174 %', 'severe_toxic': '0.05812942981719971 %', 'obscene': '0.2048194408416748 %', 'threat': '0.08640885353088379 %', 'insult': '0.5824130028486252 %', 'identity_hate': '0.07198824314400554 %'} \n",
            "\n",
            "{'toxic': '9.895411133766174 %', 'severe_toxic': '0.05812942981719971 %', 'obscene': '0.2048194408416748 %', 'threat': '0.08640885353088379 %', 'insult': '0.5824130028486252 %', 'identity_hate': '0.07198824314400554 %'} \n",
            "\n",
            "{'toxic': '9.895411133766174 %', 'severe_toxic': '0.05812942981719971 %', 'obscene': '0.2048194408416748 %', 'threat': '0.08640885353088379 %', 'insult': '0.5824130028486252 %', 'identity_hate': '0.07198824314400554 %'} \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ss-W3jZt7E5V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}